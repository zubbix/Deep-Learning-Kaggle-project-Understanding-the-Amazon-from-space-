{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train_class\n",
    "\n",
    "train_df= pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore train labels distribution\n",
    "\n",
    "labels = train_df['tags'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts = defaultdict(int) #dictionary containing each individual label\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "\n",
    "tag_list=list(counts.keys()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary assigning a numerical value to each label\n",
    "label_map = {i:j for j, i in enumerate(tag_list)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the training labels. Convert the images into pixels and resize them\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for img_name, label in tqdm(train_df.values, miniters = 1000):\n",
    "  target = np.zeros(17)\n",
    "  for tag in label.split(' '):\n",
    "    target[label_map[tag]]=1\n",
    "  X_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img_name)), (64,64)))\n",
    "  y_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.array(X_train)/255.0\n",
    "y_train = np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the trains into validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    " \n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "\t# clip predictions\n",
    "\ty_pred = backend.clip(y_pred, 0, 1)\n",
    "\t# calculate elements\n",
    "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\t# calculate precision\n",
    "\tp = tp / (tp + fp + backend.epsilon())\n",
    "\t# calculate recall\n",
    "\tr = tp / (tp + fn + backend.epsilon())\n",
    "\t# calculate fbeta, averaged across each class\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "\treturn fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "          \n",
    "# base model. Feel free to try out other architectures and ideas to improve fbeta score\n",
    "\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(64, 5, 2, activation = \"relu\", input_shape = (64, 64, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "          \n",
    "model.add(Conv2D(128, (3,3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "          \n",
    "model.add(Flatten())\n",
    "          \n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [fbeta])\n",
    "model.fit(X_train, y_train, validation_data = (x_val, y_val), epochs = 50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Amazon_Model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_sample= pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n",
    "submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img= submission_sample[0: 40669]\n",
    "files= submission_sample[40669: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the test images to pixels and resize them as well\n",
    "\n",
    "X_test=[]\n",
    "for img_name, label in tqdm(submission_sample[:40669].values, miniters = 1000):\n",
    "  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img_name)), (64, 64)))\n",
    "for img_name, label in tqdm(submission_sample[40669:].values, miniters = 1000):\n",
    "  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img_name)), (64, 64)))\n",
    "\n",
    "X_test = np.array(X_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "p_test = model.predict(X_test)\n",
    "y_pred.append(p_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = ['haze', 'primary', 'agriculture', 'clear', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'cloudy', 'partly_cloudy', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']\n",
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(y_pred[0])\n",
    "for i in range(1, len(y_pred)):\n",
    "    result += np.array(y_pred[i])\n",
    "result = pd.DataFrame(result, columns=labels1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating the probability predictions to the unique labels\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.loc[[i]]\n",
    "    a = a.apply(lambda x: x>0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the tags columns with the predicted labels\n",
    "submission_sample['tags'] = preds\n",
    "submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframe to a csv file for submission\n",
    "submission_sample.to_csv('Amazon Project_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
